#!/usr/bin/env python3
"""
ç›´æ¥ä½¿ç”¨ JSONL æ•°æ®æµ‹è¯• vLLM API
æ”¯æŒå¤šèŠ‚ç‚¹è´Ÿè½½å‡è¡¡
"""

import json
import time
import argparse
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
from queue import Queue
import random

class VLLMBenchmark:
    def __init__(self, hosts, max_output_tokens=1024, model_name=None):
        """
        Args:
            hosts: list of (host, port) tuples
            max_output_tokens: æœ€å¤§è¾“å‡º token æ•°
            model_name: æ¨¡å‹åç§°ï¼ˆé»˜è®¤ä½¿ç”¨æ¨¡å‹è·¯å¾„ï¼‰
        """
        self.hosts = hosts
        self.base_urls = [f"http://{host}:{port}/v1" for host, port in hosts]
        self.max_output_tokens = max_output_tokens
        self.model_name = model_name or "/workspace/Qwen3-8B"
        self.host_counter = 0  # ç”¨äº round-robin
        
    def get_next_url(self, strategy='round-robin'):
        """è·å–ä¸‹ä¸€ä¸ª URL"""
        if strategy == 'round-robin':
            url = self.base_urls[self.host_counter % len(self.base_urls)]
            self.host_counter += 1
            return url
        elif strategy == 'random':
            return random.choice(self.base_urls)
        else:
            return self.base_urls[0]
    
    def send_request(self, item, thread_id, strategy='round-robin'):
        """å‘é€å•ä¸ªè¯·æ±‚"""
        base_url = self.get_next_url(strategy)
        
        # æ„å»ºæ¶ˆæ¯
        system_prompt = item.get('system_prompt', 'You are a helpful assistant')
        user_prompt = item.get('prompt', '')
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        payload = {
            "model": self.model_name,
            "messages": messages,
            "max_tokens": self.max_output_tokens,
            "temperature": 1.0,
            "stream": True,
            "stream_options": {"include_usage": True}
        }
        
        headers = {"Content-Type": "application/json"}
        
        try:
            start_time = time.time()
            response = requests.post(
                f"{base_url}/chat/completions",
                headers=headers,
                json=payload,
                stream=True,
                timeout=300
            )
            
            first_token_time = None
            response_content = ""
            token_count = 0
            last_chunk = None
            
            if response.status_code == 200:
                for chunk_bytes in response.iter_lines():
                    chunk_bytes = chunk_bytes.strip()
                    if not chunk_bytes:
                        continue
                    
                    chunk = chunk_bytes.decode("utf-8").removeprefix("data: ")
                    
                    if chunk == "[DONE]":
                        break
                    
                    try:
                        data = json.loads(chunk)
                        
                        if "usage" in data:
                            last_chunk = data
                        
                        if choices := data.get("choices"):
                            if first_token_time is None:
                                first_token_time = time.time()
                            
                            delta_content = choices[0]["delta"].get("content")
                            if delta_content:
                                response_content += delta_content
                                token_count += 1
                    except json.JSONDecodeError:
                        continue
                
                end_time = time.time()
                
                # æå– usage ä¿¡æ¯
                prompt_tokens = last_chunk["usage"]["prompt_tokens"] if last_chunk else 0
                completion_tokens = last_chunk["usage"]["completion_tokens"] if last_chunk else token_count
                
                ttft = first_token_time - start_time if first_token_time else 0
                total_time = end_time - start_time
                decode_time = end_time - first_token_time if first_token_time else 0
                
                result = {
                    'success': True,
                    'base_url': base_url,
                    'thread_id': thread_id,
                    'prompt_tokens': prompt_tokens,
                    'completion_tokens': completion_tokens,
                    'ttft': ttft,
                    'total_time': total_time,
                    'decode_time': decode_time,
                    'prefill_speed': prompt_tokens / ttft if ttft > 0 else 0,
                    'decode_speed': (completion_tokens - 1) / decode_time if decode_time > 0 else 0,
                    'start_time': start_time,
                    'first_token_time': first_token_time,
                    'end_time': end_time,
                }
                
                print(f"[Thread {thread_id}] URL: {base_url}, "
                      f"Prompt: {prompt_tokens} tokens, "
                      f"TTFT: {ttft:.3f}s, "
                      f"Prefill: {result['prefill_speed']:.1f} tok/s, "
                      f"Completion: {completion_tokens} tokens, "
                      f"Decode: {result['decode_speed']:.1f} tok/s")
                
                return result
            else:
                print(f"[Thread {thread_id}] ERROR: HTTP {response.status_code} from {base_url}")
                return {'success': False, 'error': f"HTTP {response.status_code}"}
                
        except Exception as e:
            print(f"[Thread {thread_id}] ERROR: {e} from {base_url}")
            return {'success': False, 'error': str(e)}
    
    def run_benchmark(self, jsonl_file, num_requests, concurrency, strategy='round-robin', start_line=0):
        """è¿è¡Œ benchmark"""
        
        # è¯»å–æ•°æ®
        print(f"è¯»å–æ•°æ®æ–‡ä»¶: {jsonl_file}")
        with open(jsonl_file, 'r', encoding='utf-8') as f:
            all_data = [json.loads(line) for line in f if line.strip()]
        
        print(f"æ€»æ•°æ®é‡: {len(all_data)}")
        print(f"èµ·å§‹è¡Œ: {start_line}")
        print(f"è¯·æ±‚æ•°: {num_requests}")
        print(f"å¹¶å‘æ•°: {concurrency}")
        print(f"åˆ†å‘ç­–ç•¥: {strategy}")
        print(f"ç›®æ ‡èŠ‚ç‚¹: {len(self.hosts)}")
        for i, (host, port) in enumerate(self.hosts, 1):
            print(f"  èŠ‚ç‚¹ {i}: {host}:{port}")
        print("")
        
        # é€‰æ‹©æ•°æ®
        if start_line + num_requests > len(all_data):
            # å¾ªç¯ä½¿ç”¨æ•°æ®
            data_to_test = (all_data[start_line:] + all_data * ((num_requests // len(all_data)) + 1))[:num_requests]
        else:
            data_to_test = all_data[start_line:start_line + num_requests]
        
        # Shuffle ç­–ç•¥ï¼šæ‰“ä¹±æ•°æ®é¡ºåº
        if strategy == 'shuffle':
            print(f"ğŸ“Š Shuffle ç­–ç•¥ï¼šæ‰“ä¹±æ•°æ®é¡ºåºåä½¿ç”¨ round-robin åˆ†å‘")
            import random as shuffle_random
            shuffle_random.shuffle(data_to_test)
            print(f"   æ•°æ®å·²éšæœºæ‰“ä¹±")
            # æ‰“ä¹±åä½¿ç”¨ round-robin
            actual_strategy = 'round-robin'
        else:
            actual_strategy = strategy
        
        print(f"å®é™…æµ‹è¯•æ•°æ®é‡: {len(data_to_test)}")
        print("")
        
        # å¹¶å‘æµ‹è¯•
        results = []
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=concurrency) as executor:
            futures = [
                executor.submit(self.send_request, item, i, actual_strategy)
                for i, item in enumerate(data_to_test)
            ]
            
            for future in as_completed(futures):
                result = future.result()
                if result.get('success'):
                    results.append(result)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # ç»Ÿè®¡ç»“æœ
        if not results:
            print("æ²¡æœ‰æˆåŠŸçš„è¯·æ±‚ï¼")
            return
        
        print("\n" + "="*80)
        print(" Benchmark ç»“æœ")
        print("="*80)
        
        # åŸºç¡€ç»Ÿè®¡
        total_requests = len(results)
        total_prompt_tokens = sum(r['prompt_tokens'] for r in results)
        total_completion_tokens = sum(r['completion_tokens'] for r in results)
        total_tokens = total_prompt_tokens + total_completion_tokens
        
        # å»¶è¿Ÿç»Ÿè®¡
        ttfts = [r['ttft'] for r in results]
        ttfts.sort()
        
        decode_speeds = [r['decode_speed'] for r in results if r['decode_speed'] > 0]
        decode_speeds.sort()
        
        # æ‰“å°ç»Ÿè®¡
        print(f"\nè¯·æ±‚ç»Ÿè®¡:")
        print(f"  æ€»è¯·æ±‚æ•°: {total_requests}")
        print(f"  æˆåŠŸç‡: {total_requests / num_requests * 100:.1f}%")
        print(f"  æ€»è€—æ—¶: {total_time:.2f}s")
        print(f"  QPS: {total_requests / total_time:.2f}")
        
        print(f"\nToken ç»Ÿè®¡:")
        print(f"  æ€» Prompt Tokens: {total_prompt_tokens}")
        print(f"  æ€» Completion Tokens: {total_completion_tokens}")
        print(f"  æ€» Tokens: {total_tokens}")
        print(f"  å¹³å‡ Prompt é•¿åº¦: {total_prompt_tokens / total_requests:.1f}")
        print(f"  å¹³å‡ Completion é•¿åº¦: {total_completion_tokens / total_requests:.1f}")
        
        print(f"\nååé‡:")
        print(f"  ç«¯åˆ°ç«¯åå: {total_tokens / total_time:.2f} tokens/s")
        print(f"  Prefill åå: {total_prompt_tokens / sum(ttfts):.2f} tokens/s")
        print(f"  Decode åå: {total_completion_tokens / sum(r['decode_time'] for r in results):.2f} tokens/s")
        
        print(f"\nTTFT (Time to First Token):")
        print(f"  å¹³å‡: {sum(ttfts) / len(ttfts):.3f}s")
        print(f"  ä¸­ä½æ•°: {ttfts[len(ttfts)//2]:.3f}s")
        print(f"  P95: {ttfts[int(len(ttfts)*0.95)]:.3f}s")
        print(f"  P99: {ttfts[int(len(ttfts)*0.99)]:.3f}s")
        
        print(f"\nDecode é€Ÿåº¦:")
        print(f"  å¹³å‡: {sum(decode_speeds) / len(decode_speeds):.2f} tokens/s")
        print(f"  ä¸­ä½æ•°: {decode_speeds[len(decode_speeds)//2]:.2f} tokens/s")
        print(f"  P95: {decode_speeds[int(len(decode_speeds)*0.95)]:.2f} tokens/s")
        print(f"  P99: {decode_speeds[int(len(decode_speeds)*0.99)]:.2f} tokens/s")
        
        # æŒ‰èŠ‚ç‚¹ç»Ÿè®¡
        print(f"\næ¯ä¸ªèŠ‚ç‚¹çš„è¯·æ±‚åˆ†å¸ƒ:")
        for base_url in self.base_urls:
            count = sum(1 for r in results if r['base_url'] == base_url)
            print(f"  {base_url}: {count} è¯·æ±‚ ({count/total_requests*100:.1f}%)")
        
        print("\n" + "="*80)

def main():
    parser = argparse.ArgumentParser(description='vLLM JSONL Benchmark')
    parser.add_argument('--jsonl', type=str, required=True, help='JSONL æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--hosts', type=str, required=True, help='èŠ‚ç‚¹åˆ—è¡¨ï¼Œæ ¼å¼: host1:port1,host2:port2')
    parser.add_argument('--num-requests', type=int, default=1000, help='è¯·æ±‚æ•°é‡')
    parser.add_argument('--concurrency', type=int, default=64, help='å¹¶å‘æ•°')
    parser.add_argument('--max-tokens', type=int, default=1024, help='æœ€å¤§è¾“å‡º token æ•°')
    parser.add_argument('--model', type=str, default='/workspace/Qwen3-8B', help='æ¨¡å‹åç§°')
    parser.add_argument('--strategy', type=str, default='round-robin', 
                       choices=['round-robin', 'random', 'shuffle'], 
                       help='è´Ÿè½½å‡è¡¡ç­–ç•¥: round-robin(è½®è¯¢), random(éšæœº), shuffle(æ‰“ä¹±åè½®è¯¢)')
    parser.add_argument('--start-line', type=int, default=0, help='èµ·å§‹è¡Œå·')
    
    args = parser.parse_args()
    
    # è§£æ hosts
    hosts = []
    for host_str in args.hosts.split(','):
        host, port = host_str.strip().split(':')
        hosts.append((host, int(port)))
    
    # è¿è¡Œ benchmark
    benchmark = VLLMBenchmark(hosts, args.max_tokens, args.model)
    benchmark.run_benchmark(
        args.jsonl,
        args.num_requests,
        args.concurrency,
        args.strategy,
        args.start_line
    )

if __name__ == '__main__':
    main()

